{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import requests\n",
    "import pandas \n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://www.douban.com/group/584670/discussion?start={}'\n",
    "header = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'}\n",
    "cookie = {\n",
    "    'Cookie' : 'bid=rCKJ1ccjfJM; ps=y; _ga=GA1.2.598336956.1515936642; ue=\"aukuno@126.com\"; ll=\"118172\"; push_noty_num=0; push_doumail_num=0; _vwo_uuid_v2=5EE2B23ED70861CBF401713BF5739F6E|cdabff73c824987481a3cf946d2bf101; __utma=30149280.598336956.1515936642.1516178373.1516181473.5; __utmb=30149280.24.5.1516183296185; __utmc=30149280; __utmz=30149280.1516075309.2.2.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __utmv=30149280.6554'\n",
    "}\n",
    "\n",
    "# 2018-1-18 18:35:40 代理还没有解决\n",
    "proxies = {\n",
    "  \"http\": \"http://175.174.122.234:80\",\n",
    "#   \"https\": \"http://10.10.1.10:1080\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    HEAD              IP  PORT\n",
      "0   HTTP  122.114.31.177   808\n",
      "1   HTTP    61.135.217.7    80\n",
      "2  HTTPS  219.138.58.147  3128\n",
      "3  HTTPS  219.232.165.36  8080\n",
      "4  HTTPS  139.199.170.73    80\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "with open('proxies.csv') as csvfile:\n",
    "   proxy_df = pandas.read_csv(csvfile)\n",
    "print(proxy_df.head())\n",
    "iterator  = proxy_df.iterrows()\n",
    "print(len(pandas.Series(next(iterator))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    HEAD              IP  PORT                     CONCATED\n",
      "0   HTTP  122.114.31.177   808    HTTP://122.114.31.177:808\n",
      "1   HTTP    61.135.217.7    80       HTTP://61.135.217.7:80\n",
      "2  HTTPS  219.138.58.147  3128  HTTPS://219.138.58.147:3128\n",
      "3  HTTPS  219.232.165.36  8080  HTTPS://219.232.165.36:8080\n",
      "4  HTTPS  139.199.170.73    80    HTTPS://139.199.170.73:80\n"
     ]
    }
   ],
   "source": [
    "proxy_df['CONCATED'] = proxy_df.HEAD.map(str) + \"://\" +proxy_df.IP.map(str) +':'+ proxy_df.PORT.map(str)\n",
    "print(proxy_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write2csv(inform):\n",
    "    \n",
    "    dataFrame = pandas.DataFrame(inform)\n",
    "    # print(dataFrame)\n",
    "    #2018-1-18 09:46:51\n",
    "    # 发现在windows上查看该文件有乱码现象，在打开文件时加入encoding可以避免该问题\n",
    "    with open('inform.csv', 'a+', encoding='utf-8-sig') as csvfile:\n",
    "        dataFrame.to_csv(csvfile, header=False)\n",
    "        csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getElement(url):\n",
    "    response = requests.get(url, headers = header, cookies = cookie, proxies=proxies)\n",
    "    if response.status_code == 200:\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'html5lib')\n",
    "        tds = soup.find_all(\"td\", class_ = 'title')\n",
    "        inform = []\n",
    "        for tit in tds:\n",
    "            a = tit.find('a')\n",
    "            href = a.get('href')\n",
    "            title = a.get('title')\n",
    "#             time = a.next_sibling.next_sibling.next_sibling.get('time')\n",
    "            inform.append([href, title])\n",
    "        return inform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = 90\n",
    "index = pages * 25\n",
    "\n",
    "import numpy as np\n",
    "with open('inform.csv', 'a+', encoding='utf-8-sig') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['index', 'href', 'title'])\n",
    "\n",
    "for i in np.arange(0, index + 1, 25):\n",
    "    url = url.format(str(i))\n",
    "    infor = getElement(url)\n",
    "    write2csv(infor)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
